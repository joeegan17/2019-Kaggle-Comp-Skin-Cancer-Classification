{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:\\\\Users\\\\Joe\\\\Desktop\\\\Data Science Masters\\\\Independent\\\\Tensorflow\\\\Skin Cancer Project\\\\Project\\\\Images\\\\'\n",
    "train = 'data\\\\train\\\\'\n",
    "test = 'data\\\\test\\\\'\n",
    "validation = 'data\\\\validation\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrandom.seed(seed)\\n\\nos.makedirs(train + 'benign\\\\')\\nos.makedirs(train + 'malignant\\\\')\\nos.makedirs(test + 'benign\\\\')\\nos.makedirs(test + 'malignant\\\\')\\nos.makedirs(validation + 'benign\\\\')\\nos.makedirs(validation + 'malignant\\\\')\\n\\n\\ntest_examples = train_examples = validation_examples = 0\\n\\nfor line in open('labels.csv').readlines()[1:]:\\n    split_line = line.split(',')\\n    img_file = split_line[0]\\n    benign_malign = split_line[1]\\n\\n    random_num = random.random()\\n\\n    if random_num< 0.8:\\n        location = train\\n        train_examples += 1\\n    elif random_num < 0.9:\\n        location = validation\\n        validation_examples += 1\\n    else:\\n        location = test\\n        test_examples += 1\\n\\n    if int(float(benign_malign)) == 0:\\n        shutil.copy(\\n            directory + img_file + '.jpg',\\n            location + 'benign\\\\' + img_file + '.jpg'\\n        )\\n    elif int(float(benign_malign)) == 1:\\n        shutil.copy(\\n            directory + img_file + '.jpg',\\n            location + 'malignant\\\\' + img_file + '.jpg'\\n        )\\nprint(f'Number of training examples: {train_examples}')\\nprint(f'Number of validation examples {validation_examples}')\\nprint(f'Number of test examples {test_examples}')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "random.seed(seed)\n",
    "\n",
    "os.makedirs(train + 'benign\\\\')\n",
    "os.makedirs(train + 'malignant\\\\')\n",
    "os.makedirs(test + 'benign\\\\')\n",
    "os.makedirs(test + 'malignant\\\\')\n",
    "os.makedirs(validation + 'benign\\\\')\n",
    "os.makedirs(validation + 'malignant\\\\')\n",
    "\n",
    "\n",
    "test_examples = train_examples = validation_examples = 0\n",
    "\n",
    "for line in open('labels.csv').readlines()[1:]:\n",
    "    split_line = line.split(',')\n",
    "    img_file = split_line[0]\n",
    "    benign_malign = split_line[1]\n",
    "\n",
    "    random_num = random.random()\n",
    "\n",
    "    if random_num< 0.8:\n",
    "        location = train\n",
    "        train_examples += 1\n",
    "    elif random_num < 0.9:\n",
    "        location = validation\n",
    "        validation_examples += 1\n",
    "    else:\n",
    "        location = test\n",
    "        test_examples += 1\n",
    "\n",
    "    if int(float(benign_malign)) == 0:\n",
    "        shutil.copy(\n",
    "            directory + img_file + '.jpg',\n",
    "            location + 'benign\\\\' + img_file + '.jpg'\n",
    "        )\n",
    "    elif int(float(benign_malign)) == 1:\n",
    "        shutil.copy(\n",
    "            directory + img_file + '.jpg',\n",
    "            location + 'malignant\\\\' + img_file + '.jpg'\n",
    "        )\n",
    "print(f'Number of training examples: {train_examples}')\n",
    "print(f'Number of validation examples {validation_examples}')\n",
    "print(f'Number of test examples {test_examples}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = 20225\n",
    "test_examples = 2555\n",
    "validation_examples = 2551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    hub.KerasLayer('https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1', trainable=True),\n",
    "    layers.Dense(128, activation = 'relu', kernel_regularizer = keras.regularizers.L2(l2=0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(1, activation = 'sigmoid')\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255,\n",
    "    rotation_range = 15,\n",
    "    zoom_range = (0.95, 0.95),\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    data_format = 'channels_last',\n",
    "    #dtype = float32\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255, #dtype = float32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1.0/255, #dtype = float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20225 images belonging to 2 classes.\n",
      "Found 2551 images belonging to 2 classes.\n",
      "Found 2555 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_datagen.flow_from_directory(\n",
    "    'data\\\\train\\\\', target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, color_mode = 'rgb', class_mode = 'binary', shuffle=True, seed=123\n",
    ")\n",
    "\n",
    "validation_gen = validation_datagen.flow_from_directory(\n",
    "    'data\\\\validation\\\\', target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, color_mode = 'rgb', class_mode = 'binary', shuffle=True, seed=123\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    'data\\\\test\\\\', target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, color_mode = 'rgb', class_mode = 'binary', shuffle=True, seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics = METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1264/1264 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.9346 - precision: 0.8409 - recall: 0.7841 - auc: 0.9672INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 524s 414ms/step - loss: 0.2951 - accuracy: 0.9346 - precision: 0.8409 - recall: 0.7841 - auc: 0.9672 - val_loss: 0.4019 - val_accuracy: 0.9037 - val_precision: 0.7692 - val_recall: 0.6349 - val_auc: 0.9154\n",
      "Epoch 2/8\n",
      "1264/1264 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.9357 - precision: 0.8417 - recall: 0.7902 - auc: 0.9696INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 493s 390ms/step - loss: 0.2878 - accuracy: 0.9357 - precision: 0.8417 - recall: 0.7902 - auc: 0.9696 - val_loss: 0.4057 - val_accuracy: 0.8931 - val_precision: 0.7179 - val_recall: 0.6335 - val_auc: 0.9076\n",
      "Epoch 3/8\n",
      "1264/1264 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.9416 - precision: 0.8671 - recall: 0.7966 - auc: 0.9722INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 551s 436ms/step - loss: 0.2787 - accuracy: 0.9416 - precision: 0.8671 - recall: 0.7966 - auc: 0.9722 - val_loss: 0.3676 - val_accuracy: 0.9100 - val_precision: 0.7344 - val_recall: 0.7494 - val_auc: 0.9352\n",
      "Epoch 4/8\n",
      "1264/1264 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.9472 - precision: 0.8799 - recall: 0.8171 - auc: 0.9757INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 547s 433ms/step - loss: 0.2673 - accuracy: 0.9472 - precision: 0.8799 - recall: 0.8171 - auc: 0.9757 - val_loss: 0.4435 - val_accuracy: 0.8939 - val_precision: 0.7422 - val_recall: 0.5941 - val_auc: 0.8909\n",
      "Epoch 5/8\n",
      "1264/1264 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.9500 - precision: 0.8820 - recall: 0.8329 - auc: 0.9779INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 543s 430ms/step - loss: 0.2562 - accuracy: 0.9500 - precision: 0.8820 - recall: 0.8329 - auc: 0.9779 - val_loss: 0.4598 - val_accuracy: 0.8927 - val_precision: 0.7079 - val_recall: 0.6485 - val_auc: 0.9048\n",
      "Epoch 6/8\n",
      "1264/1264 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.9503 - precision: 0.8810 - recall: 0.8357 - auc: 0.9795INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 568s 449ms/step - loss: 0.2520 - accuracy: 0.9503 - precision: 0.8810 - recall: 0.8357 - auc: 0.9795 - val_loss: 0.4552 - val_accuracy: 0.8789 - val_precision: 0.6400 - val_recall: 0.6893 - val_auc: 0.8924\n",
      "Epoch 7/8\n",
      "1264/1264 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.9530 - precision: 0.8874 - recall: 0.8453 - auc: 0.9806INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 591s 468ms/step - loss: 0.2478 - accuracy: 0.9530 - precision: 0.8874 - recall: 0.8453 - auc: 0.9806 - val_loss: 0.4533 - val_accuracy: 0.8986 - val_precision: 0.7191 - val_recall: 0.6765 - val_auc: 0.9007\n",
      "Epoch 8/8\n",
      "1264/1264 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9543 - precision: 0.8865 - recall: 0.8550 - auc: 0.9825INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: efficientnet_model_beyond_twelve\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 616s 487ms/step - loss: 0.2408 - accuracy: 0.9543 - precision: 0.8865 - recall: 0.8550 - auc: 0.9825 - val_loss: 0.4062 - val_accuracy: 0.9025 - val_precision: 0.7526 - val_recall: 0.6538 - val_auc: 0.9082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c56bcb69d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen, epochs = 8, steps_per_epoch=train_examples//batch_size, validation_data=validation_gen, validation_steps = validation_examples//batch_size,\n",
    "callbacks=[keras.callbacks.ModelCheckpoint('efficientnet_model_beyond_twelve', save_best_only=False, monitor='val_auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 1280)              4049564   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,217,693\n",
      "Trainable params: 4,175,677\n",
      "Non-trainable params: 42,016\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 34s 208ms/step - loss: 0.5642 - accuracy: 0.8008 - precision: 0.4651 - recall: 0.8559 - auc: 0.9124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5642102360725403,\n",
       " 0.8007827997207642,\n",
       " 0.4650602340698242,\n",
       " 0.8558758497238159,\n",
       " 0.9124125838279724]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.evaluate(test_gen) after twelve epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 37s 227ms/step - loss: 0.4245 - accuracy: 0.8892 - precision: 0.6900 - recall: 0.6763 - auc: 0.9044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4244541823863983,\n",
       " 0.8892368078231812,\n",
       " 0.6900452375411987,\n",
       " 0.6762749552726746,\n",
       " 0.9043944478034973]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: twenty_epoch_full_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: twenty_epoch_full_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(filepath='twenty_epoch_full_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2af03d7e22c24bf2e6d190a35b261c407267ffc2225e910495761a73f1323185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
